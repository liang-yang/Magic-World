<!-- toc -->

# Scikit-Learn


## TODO

- 【Ordinary Least Squares】中，如下内容待补充：

- 什么是L1，L2 范数（L1-norm, L2-norm）？[参考](https://www.jianshu.com/p/6cf5d60db634)
- 最小二乘法的求解提到矩阵的奇异值分解，“奇异值分解”待补充。

- 【Ridge Regression】中，补充 [sklearn.linear_model.Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) 中的 solver 参数各个选项的算法：svd、cholesky、sparse_cg、lsqr、sag、saga；

- 【Tuning Hyper-Parameters】中，还需要补充其他非网格搜索的超参数调优的方案，具体在算法模型涉及到时补充；

- 【Dataset Generations】中，根据输入参数人为控制统计属性生成数据集，在各种算法模型详细分析过程中补充。参考 [Alternatives to brute force parameter search](https://scikit-learn.org/stable/modules/grid_search.html#alternatives-to-brute-force-parameter-search)、[sklearn.linear_model.ElasticNetCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html)、[cross-validation estimator](https://scikit-learn.org/stable/glossary.html#term-cross-validation-estimator)；

## Reference

- https://scikit-learn.org/stable/user_guide.html

