<!-- toc -->

# 分类模型的评估

> 本文以四分类举例，样本集合为 $$ S $$，分类类别集合为 $$ C=\{c_1, c_2, c_3, c_4\} $$

## 1. 预测结果的分类

对于所有分类模型（不仅仅是二分类），其中每一个分类类别的预测结果均可以分为四类： 

- **TP** —— True Positive
- **FP** —— Flase Positive
- **TN** —— True Negative
- **FN** —— False Negative

-|真实结果：$$c_1$$|真实结果：$$not \space c_1$$ 
:-:|:-:|:-:
**预测结果：$$c_1$$** | $$TP_{c_1}$$ | $$FP_{c_1}$$
**预测结果：$$not \space c_1$$** | $$FN_{c_1}$$ | $$TN_{c_1}$$

## 2. Accuracy

评估分类模型的预测结果，最直观的就是看预测的准确率，即 预测结果与真实结果相同的样本数量 在 总样本 中的占比，我们称之为 **Accuracy**【准确率】：

$$
Accuracy = \frac{\sum_Q TP}{|S|} = \frac{TP_{c_1} + TP_{c_2} + TP_{c_3} + TP_{c_4}}{|S|}
$$

一般来说，Accuracy 能直观的反映预测的情况。但是，我们很难量化的定义 Accuracy 的标准。也就是说，分类模型的 Accuracy 达到多少我们可以认为这个模型是优秀的？   
举个医疗领域的例子。假设某病症的发病率为 0.01%，如果分类模型对所有输入样本均返回“未发病”，那么 Accuracy 可达到 99.99%。但是，这么“高”的 Accuracy 没有任何意义。

上面的案例中，Accuracy 失效的原因之一，是由于其是针对所有分类类别统一分析准确率，这样会掩藏部分分类类别的“不准确”，尤其是样本数量少但非常重要的分类类别。由此，我们认识到需要对各个分类类别分开分析，这就是 Precision、Recall 和 F_measure。

## 3. Precision & Recall & F_measure

### 3.1. Precision

Accuracy 是所有分类类别的预测结果的准确率，而 Precision【精确率/查准率】是指某分类类别的预测结果的准确率，例如 $$c_1$$ 的 Precision 为：

$$
Precision_{c_1} = \frac{TP_{c_1}}{TP_{c_1}+FP_{c_1}} 
$$

一般来说，Precision 越高，分类模型越好。

但是，观察公式可以发现，如果把 $$c_1$$ 的 分类判别阈值 定的很高，只在非常有把握的情况下才将样本判别为 $$c_1$$，这样可以明显提高 $$ Precision_{c_1} $$。但是，这样我们会遗漏大量的真实分类为 $$c_1$$ 的样本。因此，引入了 Recall。

### 3.2. Recall

Recall【召回率/查全率】，顾名思义，是指真实结果为某分类类别的所有样本被准确找到的比例。例如 $$c_1$$ 的 Recall 为：

$$
Recall_{c_1} = \frac{TN_{c_1}}{TN_{c_1}+FP_{c_1}}
$$

一般来说，Recall 越高，分类模型越好。

但是，观察公式可以发现，如果把 $$c_1$$ 的 分类判别阈值 定的很低，甚至所有样本均判定为 $$c_1$$，这样 $$Recall_{c_1}$$ 可以达到很高。但实际上，这样并没有意义。

### 3.3. F_measure

通过 Precision 和 Recall 的分析，我们会发现两者一般情况下是此消彼长的关系：随着判别阈值的提高，Precision 逐渐提高，Recall 逐渐降低。因此，为了统一的评估分类模型，我们定义了 F_measure：

$$
\frac{2}{F\_measure} = \frac{1}{Precision} + \frac{1}{Recall}       
$$

$$
F\_measure = \frac{2 \cdot Precision \cdot Recall}{Precision + Recall}
$$

需要注意，F_measure 依然是针对某一分类类别而定义的。  
当然，如果是在二分类中，某一分类的 F_measure 基本可以确定另一分类的 F_measure。

对比 Accuracy 我们可以看出，F_measure 能更为明确的给出量化标准，例如 F_measure 达到 99.9% 就是好的模型，而不像 Accuracy 达到 99.9% 还可能没有意义。

## 4. AP & MAP

### 4.1. AP(Average Precision)




### 4.2. MAP(Mean Average Precision)

http://alexkong.net/2013/06/introduction-to-auc-and-roc/

https://blog.csdn.net/jningwei/article/details/78955536

https://www.cnblogs.com/sddai/p/5696870.html

## 2. ROC（Receiver Operating Characteristic）

基于预测结果的四类，我们可以构建两个指标：

- $$TPR$$ : True Positive Rate，所有正样本中被预测为正的比例
    $$
    TPR = \frac{TP}{TP + FN}
    $$
- $$FPR$$ : False Positive Rate，所有负样本中被预测为正的比例
    $$
    FPR = \frac{FP}{TN + FP}
    $$

针对某一个类别，预测结果正确的比例
精确率


召回率


F_measure


准确率

